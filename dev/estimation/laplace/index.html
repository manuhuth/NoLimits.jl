<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Laplace · NoLimits.jl</title><meta name="title" content="Laplace · NoLimits.jl"/><meta property="og:title" content="Laplace · NoLimits.jl"/><meta property="twitter:title" content="Laplace · NoLimits.jl"/><meta name="description" content="Documentation for NoLimits.jl."/><meta property="og:description" content="Documentation for NoLimits.jl."/><meta property="twitter:description" content="Documentation for NoLimits.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NoLimits.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../installation/">Installation</a></li><li><a class="tocitem" href="../../capabilities/">Capabilities</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Model Building</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../model-building/">Overview</a></li><li><a class="tocitem" href="../../model-building/model-macro/">@Model</a></li><li><a class="tocitem" href="../../model-building/helpers/">@helpers</a></li><li><a class="tocitem" href="../../model-building/fixed-effects/">@fixedEffects</a></li><li><a class="tocitem" href="../../model-building/covariates/">@covariates</a></li><li><a class="tocitem" href="../../model-building/random-effects/">@randomEffects</a></li><li><a class="tocitem" href="../../model-building/pre-differential-equation/">@preDifferentialEquation</a></li><li><a class="tocitem" href="../../model-building/differential-equation/">@DifferentialEquation</a></li><li><a class="tocitem" href="../../model-building/initial-de/">@initialDE</a></li><li><a class="tocitem" href="../../model-building/formulas/">@formulas</a></li><li><a class="tocitem" href="../../model-building/universal-function-approximators/">Function Approximators (NNs + SoftTrees)</a></li></ul></li><li><a class="tocitem" href="../../data-model-construction/">Data Model Construction</a></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox" checked/><label class="tocitem" for="menuitem-6"><span class="docs-label">Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../">Overview</a></li><li class="is-active"><a class="tocitem" href>Laplace</a><ul class="internal"><li><a class="tocitem" href="#Applicability"><span>Applicability</span></a></li><li><a class="tocitem" href="#Basic-Usage"><span>Basic Usage</span></a></li><li><a class="tocitem" href="#Constructor-Options"><span>Constructor Options</span></a></li><li><a class="tocitem" href="#Fixing-Known-Random-Effect-Levels-(constants_re)"><span>Fixing Known Random-Effect Levels (<code>constants_re</code>)</span></a></li><li><a class="tocitem" href="#Accessing-Results"><span>Accessing Results</span></a></li><li><a class="tocitem" href="#Serialization"><span>Serialization</span></a></li><li><a class="tocitem" href="#Bounds-and-BlackBoxOptim"><span>Bounds and BlackBoxOptim</span></a></li></ul></li><li><a class="tocitem" href="../laplace-map/">Laplace MAP</a></li><li><a class="tocitem" href="../mcem/">MCEM</a></li><li><a class="tocitem" href="../saem/">SAEM</a></li><li><a class="tocitem" href="../mcmc/">MCMC</a></li><li><a class="tocitem" href="../vi/">VI</a></li><li><a class="tocitem" href="../mle/">MLE</a></li><li><a class="tocitem" href="../mle-map/">MAP</a></li><li><a class="tocitem" href="../multistart/">Multistart</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Uncertainty Quantification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../uncertainty-quantification/">Overview</a></li><li><a class="tocitem" href="../../uncertainty-quantification/wald/">Wald</a></li><li><a class="tocitem" href="../../uncertainty-quantification/profile-likelihood/">Profile likelihood</a></li><li><a class="tocitem" href="../../uncertainty-quantification/mcmc-based-uncertainty/">MCMC-based uncertainty</a></li></ul></li><li><a class="tocitem" href="../../plotting/">Plotting</a></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/mixed-effects-multiple-methods/">Mixed-Effects Tutorial 1: Nonlinear Random-Effects Model Across Multiple Estimation Methods</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-ode-mcem/">Mixed-Effects Tutorial 2: ODE Model with Dosing Events (MCEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-nn-saem/">Mixed-Effects Tutorial 3: Neural Differential-Equation Components (SAEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-softtree-saem/">Mixed-Effects Tutorial 4: SoftTree Differential-Equation Components (SAEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-seizure-counts-poisson-nb-mcem/">Mixed-Effects Tutorial 5: Seizure Counts with Poisson and NegativeBinomial Outcomes (MCEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-left-censored-virload50-laplace/">Mixed-Effects Tutorial 6: Left-Censored Nonlinear Model (Laplace)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-vi/">Mixed-Effects Tutorial 7: Variational Inference (VI)</a></li><li><a class="tocitem" href="../../tutorials/fixed-effects-nonlinear-mle-map/">Fixed-Effects Tutorial 1: Nonlinear Longitudinal Model (MLE + MAP)</a></li><li><a class="tocitem" href="../../tutorials/fixed-effects-vi/">Fixed-Effects Tutorial 2: Variational Inference (VI)</a></li></ul></li><li><a class="tocitem" href="../../how-to-contribute/">How to Contribute</a></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Estimation</a></li><li class="is-active"><a href>Laplace</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Laplace</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/manuhuth/NoLimits.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/manuhuth/NoLimits.jl/blob/main/docs/src/estimation/laplace.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Laplace"><a class="docs-heading-anchor" href="#Laplace">Laplace</a><a id="Laplace-1"></a><a class="docs-heading-anchor-permalink" href="#Laplace" title="Permalink"></a></h1><p>The Laplace approximation is a widely used technique for integrating out random effects in nonlinear mixed-effects models. Rather than evaluating the marginal likelihood integral exactly – which is intractable for nonlinear models – the Laplace method approximates it via a second-order Taylor expansion around the empirical Bayes (EB) mode of each individual&#39;s random-effects vector. The resulting closed-form approximation can be optimized over the fixed effects using standard gradient-based methods, combining computational efficiency with support for complex nonlinear model structures.</p><h2 id="Applicability"><a class="docs-heading-anchor" href="#Applicability">Applicability</a><a id="Applicability-1"></a><a class="docs-heading-anchor-permalink" href="#Applicability" title="Permalink"></a></h2><ul><li>Requires a model with random effects.</li><li>Requires at least one free fixed effect.</li><li>Supports nonlinear models, including ODE-based models.</li></ul><p>If the model has no random effects, <code>Laplace</code> will raise an error. Use a fixed-effects method such as <a href="../mle/"><code>MLE</code></a> or <a href="../mle-map/"><code>MAP</code></a> instead.</p><h2 id="Basic-Usage"><a class="docs-heading-anchor" href="#Basic-Usage">Basic Usage</a><a id="Basic-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Usage" title="Permalink"></a></h2><p>The following example fits a simple nonlinear mixed-effects model with a single subject-level random effect.</p><pre><code class="language-julia hljs">using NoLimits
using DataFrames
using Distributions

model = @Model begin
    @fixedEffects begin
        a = RealNumber(0.2)
        b = RealNumber(0.1)
        sigma = RealNumber(0.3, scale=:log)
    end

    @covariates begin
        t = Covariate()
    end

    @randomEffects begin
        eta_id = RandomEffect(TDist(6.0); column=:ID)
    end

    @formulas begin
        mu = a + b * t + exp(eta_id)   # nonlinear in random effects
        y ~ Normal(mu, sigma)
    end
end

df = DataFrame(
    ID = [:A, :A, :B, :B, :C, :C],
    t = [0.0, 1.0, 0.0, 1.0, 0.0, 1.0],
    y = [1.0, 1.3, 0.9, 1.2, 1.1, 1.5],
)

dm = DataModel(model, df; primary_id=:ID, time_col=:t)

res = fit_model(dm, NoLimits.Laplace(; optim_kwargs=(maxiters=100,)))</code></pre><h2 id="Constructor-Options"><a class="docs-heading-anchor" href="#Constructor-Options">Constructor Options</a><a id="Constructor-Options-1"></a><a class="docs-heading-anchor-permalink" href="#Constructor-Options" title="Permalink"></a></h2><p>The <code>Laplace</code> constructor exposes options that control the outer fixed-effects optimization, the inner EB optimization, Hessian stabilization, and the computational strategy for log-determinant gradients. Most users will only need to adjust a few of these; the defaults are chosen to work well across a range of model types.</p><pre><code class="language-julia hljs">using Optimization
using OptimizationOptimJL
using LineSearches

laplace_method = NoLimits.Laplace(;
    optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    optim_kwargs=NamedTuple(),
    adtype=Optimization.AutoForwardDiff(),
    inner_optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    inner_kwargs=NamedTuple(),
    inner_adtype=Optimization.AutoForwardDiff(),
    inner_grad_tol=:auto,
    multistart_n=50,
    multistart_k=10,
    multistart_grad_tol=:auto,
    multistart_max_rounds=1,
    multistart_sampling=:lhs,
    jitter=1e-6,
    max_tries=6,
    jitter_growth=10.0,
    adaptive_jitter=true,
    jitter_scale=1e-6,
    use_trace_logdet_grad=true,
    use_hutchinson=false,
    hutchinson_n=8,
    theta_tol=0.0,
    lb=nothing,
    ub=nothing,
)</code></pre><p>Notes:</p><ul><li><code>inner_grad_tol=:auto</code> uses method-specific defaults (<code>1e-8</code> for non-ODE, <code>1e-2</code> for ODE paths).</li><li><code>use_trace_logdet_grad=true</code> is the default gradient path for the log-determinant term.</li><li><code>use_hutchinson=true</code> activates the stochastic Hutchinson approximation for logdet-related terms.</li><li><code>lb</code>/<code>ub</code> are bounds on transformed fixed-effect parameters.</li></ul><h3 id="Option-Groups"><a class="docs-heading-anchor" href="#Option-Groups">Option Groups</a><a id="Option-Groups-1"></a><a class="docs-heading-anchor-permalink" href="#Option-Groups" title="Permalink"></a></h3><p>The constructor keywords fall into several logical groups, summarized in the table below.</p><table><tr><th style="text-align: right">Group</th><th style="text-align: right">Keywords</th><th style="text-align: right">What they control</th></tr><tr><td style="text-align: right">Outer optimization</td><td style="text-align: right"><code>optimizer</code>, <code>optim_kwargs</code>, <code>adtype</code></td><td style="text-align: right">Optimization over fixed effects.</td></tr><tr><td style="text-align: right">Inner EB optimization</td><td style="text-align: right"><code>inner_optimizer</code>, <code>inner_kwargs</code>, <code>inner_adtype</code>, <code>inner_grad_tol</code></td><td style="text-align: right">Optimization of batch-level EB modes used by Laplace objective/gradient evaluation.</td></tr><tr><td style="text-align: right">EB multistart</td><td style="text-align: right"><code>multistart_n</code>, <code>multistart_k</code>, <code>multistart_grad_tol</code>, <code>multistart_max_rounds</code>, <code>multistart_sampling</code></td><td style="text-align: right">Number/selection of initial points and restart policy for EB optimization.</td></tr><tr><td style="text-align: right">Hessian stabilization</td><td style="text-align: right"><code>jitter</code>, <code>max_tries</code>, <code>jitter_growth</code>, <code>adaptive_jitter</code>, <code>jitter_scale</code></td><td style="text-align: right">Cholesky stabilization for <code>-H</code> in log-determinant calculations.</td></tr><tr><td style="text-align: right">Logdet gradient strategy</td><td style="text-align: right"><code>use_trace_logdet_grad</code>, <code>use_hutchinson</code>, <code>hutchinson_n</code></td><td style="text-align: right">Computational path for logdet-related derivatives.</td></tr><tr><td style="text-align: right">Caching</td><td style="text-align: right"><code>theta_tol</code></td><td style="text-align: right">Reuse tolerance for objective/gradient cache across nearby fixed-effect values.</td></tr><tr><td style="text-align: right">Bounds</td><td style="text-align: right"><code>lb</code>, <code>ub</code></td><td style="text-align: right">Optional transformed-scale bounds for free fixed effects.</td></tr></table><h3 id="Inner-vs-Outer-Optimizer-Choices-(Optimization.jl-Interface)"><a class="docs-heading-anchor" href="#Inner-vs-Outer-Optimizer-Choices-(Optimization.jl-Interface)">Inner vs Outer Optimizer Choices (Optimization.jl Interface)</a><a id="Inner-vs-Outer-Optimizer-Choices-(Optimization.jl-Interface)-1"></a><a class="docs-heading-anchor-permalink" href="#Inner-vs-Outer-Optimizer-Choices-(Optimization.jl-Interface)" title="Permalink"></a></h3><p><code>Laplace</code> uses a two-level (nested) optimization scheme. Both levels dispatch through the <a href="https://docs.sciml.ai/Optimization/stable/">Optimization.jl</a> interface:</p><ul><li><strong>Outer layer</strong>: optimizes the fixed effects (<code>theta</code>) to maximize the Laplace-approximated marginal log-likelihood.</li><li><strong>Inner layer</strong>: for each outer iteration, finds the EB mode (<code>b*</code>) for each batch of random effects.</li></ul><p>Practical implications:</p><ul><li>Outer optimizer (<code>optimizer</code>, <code>optim_kwargs</code>, <code>adtype</code>)<ul><li>Runs once at the top level.</li><li>Can use local gradient methods (default <code>LBFGS</code>) or global/derivative-free methods.</li><li>If using BlackBoxOptim (<code>OptimizationBBO.*</code>), finite bounds are required.</li></ul></li><li>Inner optimizer (<code>inner_optimizer</code>, <code>inner_kwargs</code>, <code>inner_adtype</code>, <code>inner_grad_tol</code>)<ul><li>Runs repeatedly across batches and across outer iterations.</li><li>Should typically be a fast local optimizer; defaults are chosen for that path.</li><li>Tighter inner tolerances can improve objective/gradient quality but increase runtime.</li></ul></li></ul><p>Repository-verified behavior:</p><ul><li>Default outer/inner optimizers are <code>OptimizationOptimJL.LBFGS(...)</code>.</li><li>Outer BlackBoxOptim is supported with finite bounds (<code>lb</code>, <code>ub</code>); without bounds, an error is raised.</li></ul><p>Examples:</p><pre><code class="language-julia hljs">using NoLimits
using OptimizationOptimJL
using OptimizationBBO
using LineSearches

# 1) Local-gradient outer + local-gradient inner (default style)
laplace_local = NoLimits.Laplace(;
    optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    inner_optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
)

# 2) Global outer search + local inner EB solves
#    (requires finite transformed-scale bounds for free fixed effects)
lb, ub = default_bounds_from_start(dm; margin=1.0)
laplace_global_outer = NoLimits.Laplace(;
    optimizer=OptimizationBBO.BBO_adaptive_de_rand_1_bin_radiuslimited(),
    optim_kwargs=(maxiters=80,),
    lb=lb,
    ub=ub,
    inner_optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    inner_kwargs=(maxiters=40,),
)</code></pre><h3 id="Detailed-Behavior"><a class="docs-heading-anchor" href="#Detailed-Behavior">Detailed Behavior</a><a id="Detailed-Behavior-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Behavior" title="Permalink"></a></h3><p>This section provides additional detail on each option group.</p><ul><li><code>inner_grad_tol</code><ul><li><code>:auto</code> resolves to <code>1e-8</code> for non-ODE models and <code>1e-2</code> for ODE models.</li></ul></li><li><code>multistart_sampling</code><ul><li>Supported values are <code>:lhs</code> (Latin hypercube sampling) and <code>:random</code>.</li></ul></li><li><code>multistart_n</code>, <code>multistart_k</code><ul><li>Control the size of the candidate start pool and the number of starts selected for EB multistart optimization.</li></ul></li><li><code>jitter</code>, <code>max_tries</code>, <code>jitter_growth</code><ul><li>If the Cholesky factorization of <code>-H</code> fails, it is retried with increasing diagonal jitter (<code>jitter * jitter_growth^attempt</code>).</li></ul></li><li><code>adaptive_jitter</code>, <code>jitter_scale</code><ul><li>When <code>adaptive_jitter=true</code>, the initial jitter is scaled by the Hessian diagonal magnitude (<code>jitter_scale * mean(abs(diag(-H)))</code>), then bounded below by <code>jitter</code>.</li></ul></li><li><code>use_trace_logdet_grad</code><ul><li>Uses trace-based derivatives of logdet terms (default path).</li></ul></li><li><code>use_hutchinson</code>, <code>hutchinson_n</code><ul><li>Uses stochastic Hutchinson estimation for logdet derivative terms with <code>hutchinson_n</code> probe vectors.</li><li>When <code>use_hutchinson=true</code>, this path is used instead of the exact logdet gradient.</li></ul></li><li><code>theta_tol</code><ul><li>Cache tolerance for reusing objective/gradient values at nearby parameter vectors.</li><li><code>0.0</code> means reuse only for effectively identical vectors.</li></ul></li><li><code>lb</code>, <code>ub</code><ul><li>Bounds are interpreted on transformed parameters and are applied only to free fixed effects.</li><li>If constants are set via <code>constants</code>, bounds for those constant parameters are ignored.</li></ul></li></ul><h3 id="Advanced-Option-Containers"><a class="docs-heading-anchor" href="#Advanced-Option-Containers">Advanced Option Containers</a><a id="Advanced-Option-Containers-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Option-Containers" title="Permalink"></a></h3><p>For more granular control, <code>Laplace</code> also accepts structured option containers that replace the corresponding keyword groups:</p><ul><li><code>inner_options</code></li><li><code>hessian_options</code></li><li><code>cache_options</code></li><li><code>multistart_options</code></li></ul><p>When one of these is provided, it replaces the corresponding scalar keyword bundle in that option group.</p><h3 id="Tuning-Examples"><a class="docs-heading-anchor" href="#Tuning-Examples">Tuning Examples</a><a id="Tuning-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-Examples" title="Permalink"></a></h3><p>The examples below illustrate common tuning strategies for different use cases.</p><pre><code class="language-julia hljs"># Fast exploratory run
laplace_fast = NoLimits.Laplace(;
    optim_kwargs=(maxiters=60,),
    multistart_n=0,
    multistart_k=0,
)

# More robust EB search
laplace_robust = NoLimits.Laplace(;
    inner_grad_tol=1e-4,
    multistart_n=120,
    multistart_k=24,
    multistart_max_rounds=3,
    multistart_sampling=:lhs,
)

# Stochastic logdet-gradient path
laplace_hutch = NoLimits.Laplace(;
    use_hutchinson=true,
    hutchinson_n=16,
)</code></pre><h2 id="Fixing-Known-Random-Effect-Levels-(constants_re)"><a class="docs-heading-anchor" href="#Fixing-Known-Random-Effect-Levels-(constants_re)">Fixing Known Random-Effect Levels (<code>constants_re</code>)</a><a id="Fixing-Known-Random-Effect-Levels-(constants_re)-1"></a><a class="docs-heading-anchor-permalink" href="#Fixing-Known-Random-Effect-Levels-(constants_re)" title="Permalink"></a></h2><p>In some settings, certain random-effect levels are known a priori – for example, a reference group set to zero or a level estimated in a previous analysis. <code>Laplace</code> supports fixing selected random-effect levels to specified values while estimating the remaining levels via EB.</p><pre><code class="language-julia hljs">constants_re = (; eta_id=(; A=0.0))

res_fixed = fit_model(
    dm,
    NoLimits.Laplace(; optim_kwargs=(maxiters=100,));
    constants_re=constants_re,
)</code></pre><p>Validation rules for <code>constants_re</code>:</p><ul><li>Keys must match random-effect names declared in <code>@randomEffects</code>.</li><li>Level names must exist in the corresponding grouping column.</li><li>Values must have the correct dimension (scalar for univariate RE; vector for multivariate RE).</li></ul><h2 id="Accessing-Results"><a class="docs-heading-anchor" href="#Accessing-Results">Accessing Results</a><a id="Accessing-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Accessing-Results" title="Permalink"></a></h2><p>After fitting, results are accessed through the standard accessor interface.</p><pre><code class="language-julia hljs">theta_u = get_params(res; scale=:untransformed)
theta_t = get_params(res; scale=:transformed)
obj = get_objective(res)
ok = get_converged(res)

re_df = get_random_effects(res)
re_df_laplace = get_laplace_random_effects(res; flatten=true, include_constants=true)

ll = get_loglikelihood(res)</code></pre><p><code>get_random_effects</code> and <code>get_laplace_random_effects</code> each return one <code>DataFrame</code> per random effect, with rows corresponding to the levels of the grouping column (e.g., one row per individual).</p><h2 id="Serialization"><a class="docs-heading-anchor" href="#Serialization">Serialization</a><a id="Serialization-1"></a><a class="docs-heading-anchor-permalink" href="#Serialization" title="Permalink"></a></h2><p>Laplace supports serial and threaded evaluation of individual- or batch-level computations through the <code>serialization</code> keyword:</p><pre><code class="language-julia hljs">using SciMLBase

res_serial = fit_model(dm, NoLimits.Laplace(); serialization=EnsembleSerial())
res_threads = fit_model(dm, NoLimits.Laplace(); serialization=EnsembleThreads())</code></pre><h2 id="Bounds-and-BlackBoxOptim"><a class="docs-heading-anchor" href="#Bounds-and-BlackBoxOptim">Bounds and BlackBoxOptim</a><a id="Bounds-and-BlackBoxOptim-1"></a><a class="docs-heading-anchor-permalink" href="#Bounds-and-BlackBoxOptim" title="Permalink"></a></h2><p>When using a derivative-free global optimizer from BlackBoxOptim, finite bounds on all free fixed effects are required. A convenience function generates default bounds from the initial parameter values:</p><pre><code class="language-julia hljs">lb, ub = default_bounds_from_start(dm; margin=1.0)</code></pre><p>These bounds are then passed directly to the <code>Laplace</code> constructor via <code>lb</code> and <code>ub</code>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Overview</a><a class="docs-footer-nextpage" href="../laplace-map/">Laplace MAP »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 20 February 2026 17:04">Friday 20 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
