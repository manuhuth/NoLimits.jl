<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>MCEM · NoLimits.jl</title><meta name="title" content="MCEM · NoLimits.jl"/><meta property="og:title" content="MCEM · NoLimits.jl"/><meta property="twitter:title" content="MCEM · NoLimits.jl"/><meta name="description" content="Documentation for NoLimits.jl."/><meta property="og:description" content="Documentation for NoLimits.jl."/><meta property="twitter:description" content="Documentation for NoLimits.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NoLimits.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../installation/">Installation</a></li><li><a class="tocitem" href="../../capabilities/">Capabilities</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Model Building</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../model-building/">Overview</a></li><li><a class="tocitem" href="../../model-building/model-macro/">@Model</a></li><li><a class="tocitem" href="../../model-building/helpers/">@helpers</a></li><li><a class="tocitem" href="../../model-building/fixed-effects/">@fixedEffects</a></li><li><a class="tocitem" href="../../model-building/covariates/">@covariates</a></li><li><a class="tocitem" href="../../model-building/random-effects/">@randomEffects</a></li><li><a class="tocitem" href="../../model-building/pre-differential-equation/">@preDifferentialEquation</a></li><li><a class="tocitem" href="../../model-building/differential-equation/">@DifferentialEquation</a></li><li><a class="tocitem" href="../../model-building/initial-de/">@initialDE</a></li><li><a class="tocitem" href="../../model-building/formulas/">@formulas</a></li><li><a class="tocitem" href="../../model-building/universal-function-approximators/">Function Approximators (NNs + SoftTrees)</a></li></ul></li><li><a class="tocitem" href="../../data-model-construction/">Data Model Construction</a></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox" checked/><label class="tocitem" for="menuitem-6"><span class="docs-label">Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../laplace/">Laplace</a></li><li><a class="tocitem" href="../laplace-map/">Laplace MAP</a></li><li class="is-active"><a class="tocitem" href>MCEM</a><ul class="internal"><li><a class="tocitem" href="#Applicability"><span>Applicability</span></a></li><li><a class="tocitem" href="#Basic-Usage"><span>Basic Usage</span></a></li><li><a class="tocitem" href="#Constructor-Options"><span>Constructor Options</span></a></li><li><a class="tocitem" href="#Option-Groups"><span>Option Groups</span></a></li><li><a class="tocitem" href="#Constructor-Input-Reference"><span>Constructor Input Reference</span></a></li><li><a class="tocitem" href="#Detailed-Behavior"><span>Detailed Behavior</span></a></li><li><a class="tocitem" href="#Fit-Keywords"><span>Fit Keywords</span></a></li><li><a class="tocitem" href="#Optimization.jl-Interface-(M-step-and-EB)"><span>Optimization.jl Interface (M-step and EB)</span></a></li><li><a class="tocitem" href="#Accessing-Results"><span>Accessing Results</span></a></li></ul></li><li><a class="tocitem" href="../saem/">SAEM</a></li><li><a class="tocitem" href="../mcmc/">MCMC</a></li><li><a class="tocitem" href="../vi/">VI</a></li><li><a class="tocitem" href="../mle/">MLE</a></li><li><a class="tocitem" href="../mle-map/">MAP</a></li><li><a class="tocitem" href="../multistart/">Multistart</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-7" type="checkbox"/><label class="tocitem" for="menuitem-7"><span class="docs-label">Uncertainty Quantification</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../uncertainty-quantification/">Overview</a></li><li><a class="tocitem" href="../../uncertainty-quantification/wald/">Wald</a></li><li><a class="tocitem" href="../../uncertainty-quantification/profile-likelihood/">Profile likelihood</a></li><li><a class="tocitem" href="../../uncertainty-quantification/mcmc-based-uncertainty/">MCMC-based uncertainty</a></li></ul></li><li><a class="tocitem" href="../../plotting/">Plotting</a></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/mixed-effects-multiple-methods/">Mixed-Effects Tutorial 1: Nonlinear Random-Effects Model Across Multiple Estimation Methods</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-ode-mcem/">Mixed-Effects Tutorial 2: ODE Model with Dosing Events (MCEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-nn-saem/">Mixed-Effects Tutorial 3: Neural Differential-Equation Components (SAEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-softtree-saem/">Mixed-Effects Tutorial 4: SoftTree Differential-Equation Components (SAEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-seizure-counts-poisson-nb-mcem/">Mixed-Effects Tutorial 5: Seizure Counts with Poisson and NegativeBinomial Outcomes (MCEM)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-left-censored-virload50-laplace/">Mixed-Effects Tutorial 6: Left-Censored Nonlinear Model (Laplace)</a></li><li><a class="tocitem" href="../../tutorials/mixed-effects-vi/">Mixed-Effects Tutorial 7: Variational Inference (VI)</a></li><li><a class="tocitem" href="../../tutorials/fixed-effects-nonlinear-mle-map/">Fixed-Effects Tutorial 1: Nonlinear Longitudinal Model (MLE + MAP)</a></li><li><a class="tocitem" href="../../tutorials/fixed-effects-vi/">Fixed-Effects Tutorial 2: Variational Inference (VI)</a></li></ul></li><li><a class="tocitem" href="../../how-to-contribute/">How to Contribute</a></li><li><a class="tocitem" href="../../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Estimation</a></li><li class="is-active"><a href>MCEM</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>MCEM</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/manuhuth/NoLimits.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/manuhuth/NoLimits.jl/blob/main/docs/src/estimation/mcem.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="MCEM"><a class="docs-heading-anchor" href="#MCEM">MCEM</a><a id="MCEM-1"></a><a class="docs-heading-anchor-permalink" href="#MCEM" title="Permalink"></a></h1><p>The Monte Carlo Expectation-Maximization (MCEM) algorithm is a likelihood-based approach for fitting nonlinear mixed-effects models when the marginal likelihood cannot be computed in closed form. It alternates between two steps:</p><ul><li>an <strong>MCMC E-step</strong> that draws samples from the conditional distribution of random effects given the current fixed-effect estimates, and</li><li>an <strong>optimization-based M-step</strong> that updates the fixed effects by maximizing the Monte Carlo approximation of the expected complete-data log-likelihood.</li></ul><p>This formulation accommodates arbitrary nonlinear observation models, including those defined through ordinary differential equations, without requiring analytically tractable integrals over the random effects.</p><h2 id="Applicability"><a class="docs-heading-anchor" href="#Applicability">Applicability</a><a id="Applicability-1"></a><a class="docs-heading-anchor-permalink" href="#Applicability" title="Permalink"></a></h2><p>MCEM is designed for models that include both fixed and random effects:</p><ul><li>The model must declare at least one random effect and at least one free fixed effect.</li><li>Multiple random-effect grouping columns and multivariate random effects are fully supported.</li></ul><p>If fixed-effect priors are defined in the model, MCEM ignores them in its objective. To incorporate priors, use <code>LaplaceMAP</code> or <code>MCMC</code> instead.</p><h2 id="Basic-Usage"><a class="docs-heading-anchor" href="#Basic-Usage">Basic Usage</a><a id="Basic-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Usage" title="Permalink"></a></h2><p>The following example illustrates a minimal MCEM workflow with a nonlinear observation model.</p><pre><code class="language-julia hljs">using NoLimits
using DataFrames
using Distributions
using Turing

model = @Model begin
    @fixedEffects begin
        a = RealNumber(0.2)
        b = RealNumber(0.1)
        sigma = RealNumber(0.3, scale=:log)
    end

    @covariates begin
        t = Covariate()
    end

    @randomEffects begin
        eta = RandomEffect(TDist(6.0); column=:ID)
    end

    @formulas begin
        mu = a + b * t + exp(eta)   # nonlinear in random effects
        y ~ Normal(mu, sigma)
    end
end

df = DataFrame(
    ID = [:A, :A, :B, :B, :C, :C],
    t = [0.0, 1.0, 0.0, 1.0, 0.0, 1.0],
    y = [1.0, 1.3, 0.9, 1.2, 1.1, 1.5],
)

dm = DataModel(model, df; primary_id=:ID, time_col=:t)

method = NoLimits.MCEM(;
    sampler=MH(),
    turing_kwargs=(n_samples=20, n_adapt=0, progress=false),
    maxiters=10,
)

res = fit_model(dm, method)</code></pre><h2 id="Constructor-Options"><a class="docs-heading-anchor" href="#Constructor-Options">Constructor Options</a><a id="Constructor-Options-1"></a><a class="docs-heading-anchor-permalink" href="#Constructor-Options" title="Permalink"></a></h2><p>The full set of constructor arguments is shown below. All arguments have defaults and are keyword-only.</p><pre><code class="language-julia hljs">using Optimization
using OptimizationOptimJL
using LineSearches
using Turing

method = NoLimits.MCEM(;
    optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    optim_kwargs=NamedTuple(),
    adtype=Optimization.AutoForwardDiff(),
    sampler=Turing.NUTS(0.75),
    turing_kwargs=NamedTuple(),
    sample_schedule=250,
    warm_start=true,
    verbose=false,
    progress=true,
    maxiters=100,
    rtol_theta=1e-4,
    atol_theta=1e-6,
    rtol_Q=1e-4,
    atol_Q=1e-6,
    consecutive_params=3,
    ebe_optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    ebe_optim_kwargs=NamedTuple(),
    ebe_adtype=Optimization.AutoForwardDiff(),
    ebe_grad_tol=:auto,
    ebe_multistart_n=50,
    ebe_multistart_k=10,
    ebe_multistart_max_rounds=5,
    ebe_multistart_sampling=:lhs,
    ebe_rescue_on_high_grad=true,
    ebe_rescue_multistart_n=128,
    ebe_rescue_multistart_k=32,
    ebe_rescue_max_rounds=8,
    ebe_rescue_grad_tol=:auto,
    ebe_rescue_multistart_sampling=:lhs,
    lb=nothing,
    ub=nothing,
)</code></pre><h2 id="Option-Groups"><a class="docs-heading-anchor" href="#Option-Groups">Option Groups</a><a id="Option-Groups-1"></a><a class="docs-heading-anchor-permalink" href="#Option-Groups" title="Permalink"></a></h2><p>The constructor arguments are organized into the following functional groups.</p><table><tr><th style="text-align: right">Group</th><th style="text-align: right">Keywords</th><th style="text-align: right">What they control</th></tr><tr><td style="text-align: right">M-step optimizer</td><td style="text-align: right"><code>optimizer</code>, <code>optim_kwargs</code>, <code>adtype</code></td><td style="text-align: right">Optimization of fixed effects using <a href="https://docs.sciml.ai/Optimization/stable/">Optimization.jl</a>.</td></tr><tr><td style="text-align: right">E-step sampler</td><td style="text-align: right"><code>sampler</code>, <code>turing_kwargs</code>, <code>sample_schedule</code>, <code>warm_start</code></td><td style="text-align: right">Sampling random effects per iteration.</td></tr><tr><td style="text-align: right">EM stopping</td><td style="text-align: right"><code>maxiters</code>, <code>rtol_theta</code>, <code>atol_theta</code>, <code>rtol_Q</code>, <code>atol_Q</code>, <code>consecutive_params</code></td><td style="text-align: right">Iteration limit and convergence checks.</td></tr><tr><td style="text-align: right">Final EB estimation</td><td style="text-align: right"><code>ebe_*</code> and <code>ebe_rescue_*</code> options</td><td style="text-align: right">Post-fit empirical Bayes mode computation used by random-effects accessors and diagnostics.</td></tr><tr><td style="text-align: right">Bounds</td><td style="text-align: right"><code>lb</code>, <code>ub</code></td><td style="text-align: right">Optional transformed-scale bounds for free fixed effects in M-step optimization.</td></tr></table><p>The E-step sampling interface is built on <a href="https://turinglang.org/">Turing.jl</a>: the <code>sampler</code> and <code>turing_kwargs</code> arguments are forwarded to the underlying Turing sampling calls.</p><h2 id="Constructor-Input-Reference"><a class="docs-heading-anchor" href="#Constructor-Input-Reference">Constructor Input Reference</a><a id="Constructor-Input-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Constructor-Input-Reference" title="Permalink"></a></h2><h3 id="M-step-Optimization-Inputs"><a class="docs-heading-anchor" href="#M-step-Optimization-Inputs">M-step Optimization Inputs</a><a id="M-step-Optimization-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#M-step-Optimization-Inputs" title="Permalink"></a></h3><p>These arguments configure the fixed-effect optimization performed at each MCEM iteration.</p><ul><li><code>optimizer</code><ul><li>Optimizer for fixed effects in each MCEM iteration.</li><li>Default: <code>OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking())</code>.</li></ul></li><li><code>optim_kwargs</code><ul><li>Keyword arguments forwarded to <code>Optimization.solve</code> for the M-step optimizer.</li></ul></li><li><code>adtype</code><ul><li>Automatic differentiation backend for the M-step objective in <code>OptimizationFunction</code>.</li></ul></li></ul><h3 id="E-step-Sampling-Inputs"><a class="docs-heading-anchor" href="#E-step-Sampling-Inputs">E-step Sampling Inputs</a><a id="E-step-Sampling-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#E-step-Sampling-Inputs" title="Permalink"></a></h3><p>These arguments control the MCMC sampling of random effects at each iteration.</p><ul><li><code>sampler</code><ul><li>Turing sampler used for random-effect sampling in each E-step.</li><li>Default: <code>Turing.NUTS(0.75)</code>.</li></ul></li><li><code>turing_kwargs</code><ul><li>Additional keyword arguments passed through to Turing sampling calls.</li><li>The keys <code>n_samples</code> and <code>n_adapt</code> are interpreted explicitly by MCEM, then passed as sampling and adaptation sizes.</li></ul></li><li><code>sample_schedule</code><ul><li>Controls the number of MCMC samples drawn per iteration.</li><li>Accepted forms: an integer (constant across iterations), a vector (iteration-indexed), or a function <code>iter -&gt; n_samples</code>.</li><li>If a schedule value is <code>&lt;= 0</code>, MCEM falls back to <code>turing_kwargs[:n_samples]</code> (or <code>100</code> if absent).</li></ul></li><li><code>warm_start</code><ul><li>When <code>true</code>, reuses previous batch latent-state parameter values as initialization for the next E-step.</li></ul></li><li><code>verbose</code><ul><li>Enables iteration-level logging of diagnostic quantities (<code>Q</code>, <code>dtheta</code>, <code>dQ</code>, sample count).</li></ul></li><li><code>progress</code><ul><li>Enables or disables the progress bar.</li></ul></li></ul><h3 id="EM-Convergence-Inputs"><a class="docs-heading-anchor" href="#EM-Convergence-Inputs">EM Convergence Inputs</a><a id="EM-Convergence-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#EM-Convergence-Inputs" title="Permalink"></a></h3><p>MCEM monitors both fixed-effect parameter stability and Q-function stability to determine convergence.</p><ul><li><code>maxiters</code><ul><li>Maximum number of MCEM iterations.</li></ul></li><li><code>rtol_theta</code>, <code>atol_theta</code><ul><li>Relative and absolute tolerances for fixed-effect parameter stabilization.</li></ul></li><li><code>rtol_Q</code>, <code>atol_Q</code><ul><li>Relative and absolute tolerances for Q-function stabilization.</li></ul></li><li><code>consecutive_params</code><ul><li>Number of consecutive iterations that must simultaneously satisfy both parameter and Q stabilization criteria before convergence is declared.</li></ul></li></ul><h3 id="Final-EB-Mode-Inputs"><a class="docs-heading-anchor" href="#Final-EB-Mode-Inputs">Final EB Mode Inputs</a><a id="Final-EB-Mode-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#Final-EB-Mode-Inputs" title="Permalink"></a></h3><p>After the EM iterations complete, MCEM computes empirical Bayes (EB) modal estimates of the random effects. These estimates are used by downstream accessors and diagnostic functions.</p><ul><li><code>ebe_optimizer</code>, <code>ebe_optim_kwargs</code>, <code>ebe_adtype</code><ul><li>Optimizer, solve arguments, and AD backend for EB mode optimization.</li></ul></li><li><code>ebe_grad_tol</code><ul><li>Gradient tolerance for the EB optimization (<code>:auto</code> selects a data-adaptive value).</li></ul></li><li><code>ebe_multistart_n</code>, <code>ebe_multistart_k</code>, <code>ebe_multistart_max_rounds</code>, <code>ebe_multistart_sampling</code><ul><li>Multistart configuration for EB optimization, controlling the number of initial points, top candidates retained, maximum restart rounds, and sampling strategy.</li></ul></li><li><code>ebe_rescue_on_high_grad</code><ul><li>Enables a rescue multistart procedure if the final EB gradient norm remains above threshold.</li></ul></li><li><code>ebe_rescue_multistart_n</code>, <code>ebe_rescue_multistart_k</code>, <code>ebe_rescue_max_rounds</code>, <code>ebe_rescue_grad_tol</code>, <code>ebe_rescue_multistart_sampling</code><ul><li>Configuration for the rescue strategy.</li></ul></li></ul><h3 id="Bound-Inputs"><a class="docs-heading-anchor" href="#Bound-Inputs">Bound Inputs</a><a id="Bound-Inputs-1"></a><a class="docs-heading-anchor-permalink" href="#Bound-Inputs" title="Permalink"></a></h3><ul><li><code>lb</code>, <code>ub</code><ul><li>Optional transformed-scale bounds for free fixed effects in the M-step optimization.</li><li>Parameters held constant (via the <code>constants</code> fit keyword) are removed from the optimized vector; any corresponding bound entries are ignored.</li></ul></li></ul><h2 id="Detailed-Behavior"><a class="docs-heading-anchor" href="#Detailed-Behavior">Detailed Behavior</a><a id="Detailed-Behavior-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-Behavior" title="Permalink"></a></h2><p>This section provides additional details on selected options.</p><ul><li><code>sample_schedule</code><ul><li>Can be:<ul><li>an integer (constant samples per MCEM iteration),</li><li>a vector (iteration-indexed schedule),</li><li>a function <code>(iter -&gt; n_samples)</code>.</li></ul></li></ul></li><li><code>sampler</code><ul><li>Common tested choices are <code>MH()</code> and <code>NUTS(...)</code>.</li></ul></li><li>Convergence<ul><li>MCEM checks both parameter stabilization and Q stabilization.</li><li>Both must satisfy tolerances for <code>consecutive_params</code> iterations.</li></ul></li><li><code>warm_start=true</code><ul><li>Reuses previous latent-state parameterization in the E-step where possible.</li></ul></li><li><code>store_eb_modes</code> (fit keyword)<ul><li><code>true</code>: stores final EB modes in fit result.</li><li><code>false</code>: EB modes can be recomputed later when calling random-effects accessors.</li></ul></li></ul><h2 id="Fit-Keywords"><a class="docs-heading-anchor" href="#Fit-Keywords">Fit Keywords</a><a id="Fit-Keywords-1"></a><a class="docs-heading-anchor-permalink" href="#Fit-Keywords" title="Permalink"></a></h2><p>In addition to the method constructor arguments, <code>fit_model</code> accepts several keyword arguments that control data-level settings for the MCEM run.</p><pre><code class="language-julia hljs">res = fit_model(
    dm,
    method;
    constants=(a=0.2,),
    constants_re=(; eta=(; A=0.0,)),
    penalty=NamedTuple(),
    ode_args=(),
    ode_kwargs=NamedTuple(),
    serialization=EnsembleSerial(),
    rng=Random.default_rng(),
    theta_0_untransformed=nothing,
    store_eb_modes=true,
)</code></pre><p>The <code>constants_re</code> argument allows specific random-effect levels to be fixed at known values while the remaining levels are estimated.</p><h2 id="Optimization.jl-Interface-(M-step-and-EB)"><a class="docs-heading-anchor" href="#Optimization.jl-Interface-(M-step-and-EB)">Optimization.jl Interface (M-step and EB)</a><a id="Optimization.jl-Interface-(M-step-and-EB)-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization.jl-Interface-(M-step-and-EB)" title="Permalink"></a></h2><p>MCEM uses <a href="https://docs.sciml.ai/Optimization/stable/">Optimization.jl</a> in two places:</p><ol><li>The M-step optimization over fixed effects at each iteration.</li><li>The EB mode optimization (final or recomputed EB modes) through the <code>ebe_*</code> configuration.</li></ol><p>Tested M-step optimizers include:</p><ul><li><code>OptimizationOptimJL.LBFGS(...)</code> (default)</li><li><code>OptimizationOptimisers.Adam(...)</code></li><li><code>OptimizationBBO.BBO_adaptive_de_rand_1_bin_radiuslimited()</code></li></ul><p>When using derivative-free optimizers such as those from <code>OptimizationBBO</code>, finite bounds must be supplied:</p><pre><code class="language-julia hljs">using OptimizationBBO

lb, ub = default_bounds_from_start(dm; margin=1.0)

method_bbo = NoLimits.MCEM(;
    optimizer=OptimizationBBO.BBO_adaptive_de_rand_1_bin_radiuslimited(),
    optim_kwargs=(iterations=20,),
    sampler=MH(),
    turing_kwargs=(n_samples=10, n_adapt=0, progress=false),
    maxiters=5,
    lb=lb,
    ub=ub,
)</code></pre><p>The M-step and EB optimizers can be configured independently. The following example uses L-BFGS for both but with distinct iteration limits and multistart settings:</p><pre><code class="language-julia hljs">using OptimizationOptimJL
using LineSearches

method_two_stage = NoLimits.MCEM(;
    optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    optim_kwargs=(maxiters=120,),
    ebe_optimizer=OptimizationOptimJL.LBFGS(linesearch=LineSearches.BackTracking()),
    ebe_optim_kwargs=(maxiters=60,),
    ebe_grad_tol=:auto,
    ebe_multistart_n=80,
    ebe_multistart_k=16,
)</code></pre><h2 id="Accessing-Results"><a class="docs-heading-anchor" href="#Accessing-Results">Accessing Results</a><a id="Accessing-Results-1"></a><a class="docs-heading-anchor-permalink" href="#Accessing-Results" title="Permalink"></a></h2><p>After fitting, results are accessed through the standard accessor interface. MCEM returns point estimates (the EM solution) rather than a posterior chain.</p><pre><code class="language-julia hljs">theta_u = NoLimits.get_params(res; scale=:untransformed)
obj = get_objective(res)
ok = get_converged(res)

re_df = get_random_effects(res)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../laplace-map/">« Laplace MAP</a><a class="docs-footer-nextpage" href="../saem/">SAEM »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Wednesday 25 February 2026 22:17">Wednesday 25 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
